{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphX Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://spark.apache.org/docs/latest/graphx-programming-guide.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark._\n",
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Example Property Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Building a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "users = ParallelCollectionRDD[0] at parallelize at <console>:37\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at <console>:37"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Define vertices of the graph: users\n",
    "\n",
    "val users: RDD[(VertexId, (String, String))] = \n",
    "sc.parallelize(Array((3L, (\"rxin\", \"student\")), (7L, (\"jgonzal\", \"postdoc\")),\n",
    "                     (5L, (\"franklin\", \"prof\")), (2L, (\"istoica\", \"prof\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relationships = ParallelCollectionRDD[1] at parallelize at <console>:37\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[1] at parallelize at <console>:37"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create edges of the graphs: relationships\n",
    "\n",
    "val relationships: RDD[Edge[String]] = \n",
    "sc.parallelize(Array(Edge(3L, 7L, \"collab\"), Edge(5L, 3L, \"advisor\"),\n",
    "                     Edge(2L, 5L, \"colleague\"), Edge(5L, 7L, \"pi\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultUser = (John Doe,Missing)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(John Doe,Missing)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Define a default user (for relationships with missing users)\n",
    "\n",
    "val defaultUser = (\"John Doe\", \"Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graph = org.apache.spark.graphx.impl.GraphImpl@7c5b1a0\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@7c5b1a0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Build the initial graph\n",
    "\n",
    "val graph = Graph(users, relationships, defaultUser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Deconstruct a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Count all users that are postdocs\n",
    "\n",
    "graph.vertices.filter{case(id, (name, pos)) => pos == \"postdoc\"}.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Count all edges where src > dst ()\n",
    "\n",
    "graph.edges.filter{case Edge(src, dst, prop) => src > dst}.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rxinis the collab of postdoc\n",
      "franklinis the advisor of student\n",
      "istoicais the colleague of prof\n",
      "franklinis the pi of postdoc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "facts = MapPartitionsRDD[23] at map at <console>:36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[23] at map at <console>:36"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Get all the triplets to create an RDD of facts\n",
    "\n",
    "val facts: RDD[String] = graph.triplets.map(triplet => \n",
    "    triplet.srcAttr._1 + \"is the \" + triplet.attr + \" of \" + \n",
    "    triplet.dstAttr._2)\n",
    "facts.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Graph Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((3,1), (5,1), (7,2))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Example\n",
    "\n",
    "graph.inDegrees.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Property Operators\n",
    "\n",
    "* `mapVertices`\n",
    "* `mapEdges`\n",
    "* `mapTriplets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@7ac6a235"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "newGraph = org.apache.spark.graphx.impl.GraphImpl@7ac6a235\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// New graph but only with names in the vertexs\n",
    "\n",
    "val newGraph = graph.mapVertices{case(id, attr) => (attr._1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((2,(istoica,prof)), (3,(rxin,student)), (5,(franklin,prof)), (7,(jgonzal,postdoc)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.vertices.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((2,istoica), (3,rxin), (5,franklin), (7,jgonzal))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newGraph.vertices.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Structural Operators\n",
    "\n",
    "* `reverse`\n",
    "* `subgraph`\n",
    "* `mask`\n",
    "* `groupEdges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reversedGraph = org.apache.spark.graphx.impl.GraphImpl@64e9fc1f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@64e9fc1f"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reverse a graph\n",
    "\n",
    "val reversedGraph = graph.reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:40: error: not found: value subgraph\n",
       "       subgraph.vertices.collect().foreach(println)\n",
       "       ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Get a subgraph: subgraph(epred, vpred). \n",
    "// Exclude all the students from the graph\n",
    "\n",
    "val subGraph = graph.subgraph(vpred = (id, attr) => attr._2 != \"student\")\n",
    "subgraph.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:37: error: not found: value subGraph\n",
       "       val maskGraph = ccGraph.mask(subGraph)\n",
       "                                    ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// mask\n",
    "\n",
    "val ccGraph = graph.connectedComponents()\n",
    "val maskGraph = ccGraph.mask(subGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Join Operators\n",
    "\n",
    "* `joinVertices`\n",
    "* `outerJoinVertices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,(istoica,prof))\n",
      "(3,(rxin,student))\n",
      "(5,(franklin,prof))\n",
      "(7,(jgonzal,postdoc))\n"
     ]
    }
   ],
   "source": [
    "graph.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,(istoica,istoica@gmail.com))\n",
      "(3,(rxin,student))\n",
      "(5,(franklin,prof))\n",
      "(7,(jgonzal,franklin@gmail.com))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "emailsRDD = ParallelCollectionRDD[36] at parallelize at <console>:39\n",
       "graphWithEmails = org.apache.spark.graphx.impl.GraphImpl@342f5975\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@342f5975"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// joinVertices\n",
    "\n",
    "val emailsRDD: RDD[(VertexId, String)] = \n",
    "sc.parallelize(Array((2L, \"istoica@gmail.com\"), (7L, \"franklin@gmail.com\")))\n",
    "\n",
    "val graphWithEmails = graph.joinVertices(emailsRDD)((idx, a, b) => (a._1, b))\n",
    "graphWithEmails.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,(istoica,prof,istoica@gmail.com))\n",
      "(3,(rxin,student,Null))\n",
      "(5,(franklin,prof,Null))\n",
      "(7,(jgonzal,postdoc,franklin@gmail.com))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "graphWithEmailsFull = org.apache.spark.graphx.impl.GraphImpl@1a688eda\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@1a688eda"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// outerJoinVertices\n",
    "\n",
    "val graphWithEmailsFull = graph.outerJoinVertices(emailsRDD)((idx, a, b) => {\n",
    "    \n",
    "    b match {\n",
    "        \n",
    "        case Some(b) => (a._1, a._2, b)\n",
    "        case None => (a._1, a._2, \"Null\")\n",
    "    }\n",
    "    \n",
    "    \n",
    "})\n",
    "graphWithEmailsFull.vertices.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Neighborhood Aggregation\n",
    "\n",
    "* `aggregateMessages`\n",
    "* `mapReduceTriplets`\n",
    "* `degrees, inDegrees, outDegrees`\n",
    "* `collectNeighborIds`, `collectNeighbor` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array((3,1), (5,1), (7,2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.inDegrees.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxInDegree = (7,2)\n",
       "maxOutDegree = (5,2)\n",
       "maxDegree = (5,3)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "max: (a: (org.apache.spark.graphx.VertexId, Int), b: (org.apache.spark.graphx.VertexId, Int))(org.apache.spark.graphx.VertexId, Int)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5,3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Calculate the max degrees, inDegrees and outDegrees of the graph\n",
    "\n",
    "\n",
    "def max(a: (VertexId, Int), b: (VertexId, Int)): (VertexId, Int) = {\n",
    "    \n",
    "    if (a._2 > b._2) a else b\n",
    "    \n",
    "}\n",
    "\n",
    "val maxInDegree = graph.inDegrees.reduce(max)\n",
    "val maxOutDegree = graph.outDegrees.reduce(max)\n",
    "val maxDegree = graph.degrees.reduce(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "direction = EdgeDirection.Out\n",
       "neihborVertexsIds = VertexRDDImpl[76] at RDD at VertexRDD.scala:57\n",
       "neihborVertexs = VertexRDDImpl[82] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[82] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Collecting Neighbors: very expensive, use aggregateMessages instead\n",
    "\n",
    "val direction: EdgeDirection = EdgeDirection.Out\n",
    "val neihborVertexsIds = graph.collectNeighborIds(direction)\n",
    "val neihborVertexs = graph.collectNeighbors(direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Graph Algorithms\n",
    "\n",
    "* `pageRank`\n",
    "* `connectedComponents`\n",
    "* `triangleCount`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ranks = VertexRDDImpl[172] at RDD at VertexRDD.scala:57\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VertexRDDImpl[172] at RDD at VertexRDD.scala:57"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// pageRank\n",
    "\n",
    "val ranks = graph.pageRank(0.0001).vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc = org.apache.spark.graphx.impl.GraphImpl@5cef4be9\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@5cef4be9"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// conectedComponets\n",
    "\n",
    "val cc = graph.connectedComponents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tc = org.apache.spark.graphx.impl.GraphImpl@828c842\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.graphx.impl.GraphImpl@828c842"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// triangleCounts\n",
    "\n",
    "val tc = graph.triangleCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
